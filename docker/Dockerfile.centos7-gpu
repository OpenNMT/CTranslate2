FROM nvidia/cuda:10.0-cudnn7-devel-centos7 as builder

RUN yum install -y epel-release centos-release-scl-rh && \
    yum install -y \
        devtoolset-8-gcc \
        devtoolset-8-gcc-c++ \
        gcc \
        gcc-c++ \
        make \
        python3-devel \
        wget && \
    rm -rf /var/cache/yum/* && \
    python3 -m pip --no-cache-dir install --upgrade pip

WORKDIR /root

RUN wget https://cmake.org/files/v3.12/cmake-3.12.2-Linux-x86_64.tar.gz
RUN tar xf cmake-3.12.2-Linux-x86_64.tar.gz && \
    rm cmake-3.12.2-Linux-x86_64.tar.gz
ENV PATH=$PATH:/root/cmake-3.12.2-Linux-x86_64/bin

ENV MKL_VERSION=2020
ENV MKL_UPDATE=0
ENV MKL_BUILD=088
RUN yum-config-manager --add-repo https://yum.repos.intel.com/mkl/setup/intel-mkl.repo && \
    rpm --import https://yum.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS-2019.PUB && \
    yum install -y intel-mkl-64bit-$MKL_VERSION.$MKL_UPDATE-$MKL_BUILD && \
    rm -rf /var/cache/yum/*

ENV DNNL_VERSION=1.5.0
ENV DNNL_TAG=v1.5
ENV DNNL_DIR=/root/dnnl
RUN wget https://github.com/oneapi-src/oneDNN/releases/download/${DNNL_TAG}/dnnl_lnx_${DNNL_VERSION}_cpu_gomp.tgz && \
    tar xf dnnl*.tgz && \
    rm dnnl*.tgz && \
    mv dnnl* ${DNNL_DIR}

ENV TENSORRT_MAJOR_VERSION=6
ENV TENSORRT_VERSION=${TENSORRT_MAJOR_VERSION}.0.1
RUN curl -fsSL https://developer.download.nvidia.com/compute/machine-learning/repos/rhel7/x86_64/libnvinfer-devel-${TENSORRT_VERSION}-1.cuda10.0.x86_64.rpm -O && \
    curl -fsSL https://developer.download.nvidia.com/compute/machine-learning/repos/rhel7/x86_64/libnvinfer${TENSORRT_MAJOR_VERSION}-${TENSORRT_VERSION}-1.cuda10.0.x86_64.rpm -O && \
    rpm -ivh --nodeps libnvinfer*.rpm && \
    rm libnvinfer*.rpm

WORKDIR /root/ctranslate2-dev

COPY third_party third_party
COPY cli cli
COPY include include
COPY src src
COPY CMakeLists.txt .

ARG CXX_FLAGS
ENV CXX_FLAGS=${CXX_FLAGS}
ARG CUDA_NVCC_FLAGS
ENV CUDA_NVCC_FLAGS=${CUDA_NVCC_FLAGS:-"-Xfatbin -compress-all"}
ARG CUDA_ARCH_LIST
ENV CUDA_ARCH_LIST=${CUDA_ARCH_LIST:-"Common"}
ENV CTRANSLATE2_ROOT=/root/ctranslate2

RUN mkdir build && \
    cd build && \
    source scl_source enable devtoolset-8 && \
    cmake -DCMAKE_INSTALL_PREFIX=${CTRANSLATE2_ROOT} \
          -DCMAKE_PREFIX_PATH=${DNNL_DIR} -DWITH_DNNL=ON -DOPENMP_RUNTIME=COMP \
          -DWITH_CUDA=ON \
          -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="${CXX_FLAGS}" \
          -DCUDA_HOST_COMPILER=/usr/bin/cc \
          -DCUDA_NVCC_FLAGS="${CUDA_NVCC_FLAGS}" -DCUDA_ARCH_LIST="${CUDA_ARCH_LIST}" .. && \
    VERBOSE=1 make -j4 && \
    make install

ENV LANG=en_US.UTF-8
COPY README.md .
COPY python python

WORKDIR /root/ctranslate2-dev/python
RUN python3 -m pip --no-cache-dir install wheel pybind11==2.4.3 && \
    python3 -m pip freeze | grep pybind11 > /root/ctranslate2/install_requirements.txt && \
    source scl_source enable devtoolset-8 && \
    python3 setup.py bdist_wheel && \
    python3 setup.py sdist && \
    rm -r build && \
    mv dist/* /root/ctranslate2 && \
    rmdir dist

WORKDIR /root
RUN cp -P ${DNNL_DIR}/lib/*.so* /root/ctranslate2/lib64 && \
    cp -P /usr/local/cuda/lib64/libcudnn.so* /root/ctranslate2/lib64 && \
    cp -P /lib64/libnvinfer.so* /root/ctranslate2/lib64

FROM nvidia/cuda:10.0-base-centos7

RUN yum install -y epel-release && \
    yum install -y \
        cuda-cublas-$CUDA_PKG_VERSION \
        libgomp \
        python3 \
        && \
    rm -rf /var/cache/yum/* && \
    python3 -m pip --no-cache-dir install --upgrade pip

COPY --from=builder /root/ctranslate2 /opt/ctranslate2
RUN python3 -m pip --no-cache-dir install /opt/ctranslate2/*cp3*.whl

WORKDIR /opt

ENV CTRANSLATE2_ROOT=/opt/ctranslate2
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CTRANSLATE2_ROOT/lib64

ENTRYPOINT ["/opt/ctranslate2/bin/translate"]
