FROM nvidia/cuda:10.0-devel-ubuntu18.04 as builder

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        apt-transport-https \
        build-essential \
        ca-certificates \
        libboost-program-options-dev \
        libboost-python-dev \
        python-pip \
        gnupg \
        curl \
        wget && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /root

RUN wget https://cmake.org/files/v3.12/cmake-3.12.2-Linux-x86_64.tar.gz
RUN tar xf cmake-3.12.2-Linux-x86_64.tar.gz && \
    rm cmake-3.12.2-Linux-x86_64.tar.gz
ENV PATH=$PATH:/root/cmake-3.12.2-Linux-x86_64/bin

ENV MKL_VERSION=2019
ENV MKL_UPDATE=5
ENV MKL_BUILD=075
RUN wget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS-2019.PUB && \
    apt-key add GPG-PUB-KEY-INTEL-SW-PRODUCTS-*.PUB && \
    rm GPG-PUB-KEY-INTEL-SW-PRODUCTS-*.PUB && \
    echo "deb https://apt.repos.intel.com/mkl all main" > /etc/apt/sources.list.d/intel-mkl.list && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
        intel-mkl-64bit-$MKL_VERSION.$MKL_UPDATE.$MKL_BUILD && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

ENV MKLDNN_ROOT=/root/mkl-dnn
ENV MKLDNN_VERSION=0.21
RUN wget https://github.com/intel/mkl-dnn/archive/v$MKLDNN_VERSION.tar.gz && \
    tar xf v$MKLDNN_VERSION.tar.gz && rm v$MKLDNN_VERSION.tar.gz && \
    cd mkl-dnn-* && \
    mkdir build && cd build && \
    cmake -DCMAKE_INSTALL_PREFIX=${MKLDNN_ROOT} -DARCH_OPT_FLAGS="" \
          -DMKLROOT=/opt/intel/mkl -DMKLDNN_USE_MKL=FULL:STATIC -DMKLDNN_THREADING=OMP:INTEL \
          -DWITH_TEST=OFF -DWITH_EXAMPLE=OFF .. && \
    make -j4 && make install && \
    cd ../.. && rm -r mkl-dnn-*

ENV CUDNN_VERSION_SHORT=7.6.4
ENV CUDNN_VERSION=${CUDNN_VERSION_SHORT}.38
RUN curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v${CUDNN_VERSION_SHORT}/cudnn-10.0-linux-x64-v${CUDNN_VERSION}.tgz -O && \
    tar --no-same-owner -xzf cudnn-10.0-linux-x64-v${CUDNN_VERSION}.tgz -C /usr/local && \
    rm cudnn-10.0-linux-x64-v${CUDNN_VERSION}.tgz

ENV TENSORRT_MAJOR_VERSION=5
ENV TENSORRT_VERSION=${TENSORRT_MAJOR_VERSION}.1.5
RUN curl -fsSL https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libnvinfer-dev_${TENSORRT_VERSION}-1+cuda10.0_amd64.deb -O && \
    curl -fsSL https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libnvinfer${TENSORRT_MAJOR_VERSION}_${TENSORRT_VERSION}-1+cuda10.0_amd64.deb -O && \
    dpkg -i --force-depends libnvinfer*.deb && \
    rm libnvinfer*.deb

ENV CUB_VERSION=1.8.0
ENV CUB_ROOT=/root/cub
RUN wget https://github.com/NVlabs/cub/archive/v${CUB_VERSION}.tar.gz && \
    tar xf v${CUB_VERSION}.tar.gz && \
    mv cub-${CUB_VERSION} ${CUB_ROOT} && \
    rm v${CUB_VERSION}.tar.gz

WORKDIR /root/ctranslate2-dev

COPY cli cli
COPY include include
COPY src src
COPY tests tests
COPY CMakeLists.txt .

ARG CXX_FLAGS
ENV CXX_FLAGS=${CXX_FLAGS}
ARG CUDA_NVCC_FLAGS
ENV CUDA_NVCC_FLAGS=${CUDA_NVCC_FLAGS:-"-Xfatbin -compress-all"}
ARG CUDA_ARCH_LIST
ENV CUDA_ARCH_LIST=${CUDA_ARCH_LIST:-"Common"}

RUN mkdir build && \
    cd build && \
    cmake -DCMAKE_INSTALL_PREFIX=/root/ctranslate2 \
          -DCMAKE_PREFIX_PATH="${CUB_ROOT};${MKLDNN_ROOT}" \
          -DWITH_CUDA=ON -DWITH_MKLDNN=ON \
          -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="${CXX_FLAGS}" \
          -DCUDA_NVCC_FLAGS="${CUDA_NVCC_FLAGS}" -DCUDA_ARCH_LIST="${CUDA_ARCH_LIST}" .. && \
    VERBOSE=1 make -j4 && \
    make install

COPY python python

WORKDIR /root/ctranslate2-dev/python
RUN pip --no-cache-dir install setuptools wheel
RUN CTRANSLATE2_ROOT=/root/ctranslate2 python setup.py bdist_wheel

WORKDIR /root
RUN cp /opt/intel/lib/intel64/libiomp5.so /root/ctranslate2/lib && \
    cp -P /root/mkl-dnn/lib/libmkldnn.so* /root/ctranslate2/lib && \
    cp -P /usr/lib/x86_64-linux-gnu/libboost_python*.so* /root/ctranslate2/lib && \
    cp -P /usr/local/cuda/lib*/libcudnn.so* /root/ctranslate2/lib && \
    cp -P /usr/lib/x86_64-linux-gnu/libnvinfer.so* /root/ctranslate2/lib && \
    cp /root/ctranslate2-dev/python/dist/*whl /root/ctranslate2

FROM nvidia/cuda:10.0-base-ubuntu18.04

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        cuda-cublas-$CUDA_PKG_VERSION \
        python-pip && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

COPY --from=builder /root/ctranslate2 /opt/ctranslate2
RUN pip --no-cache-dir install /opt/ctranslate2/*.whl

WORKDIR /opt

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/ctranslate2/lib

ENTRYPOINT ["/opt/ctranslate2/bin/translate"]
